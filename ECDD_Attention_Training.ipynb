{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {},
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECDD Model Training Notebook (Attention Pooling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook trains the Teacher and Student models using **Attention Pooling**, strictly following the project's architecture document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Environment Setup\n",
    "This cell installs dependencies and creates all necessary scripts and configuration files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision pyyaml scikit-learn matplotlib tqdm opencv-python -q\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def write_file(path, content):\n",
    "    p = Path(path)\n",
    "    p.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(p, 'w') as f:\n",
    "        f.write(content)\n",
    "\n",
    "print(\"Creating directory structure...\")\n",
    "os.makedirs('deepfake-patch-audit/config', exist_ok=True)\n",
    "os.makedirs('deepfake-patch-audit/models/student', exist_ok=True)\n",
    "os.makedirs('deepfake-patch-audit/datasets', exist_ok=True)\n",
    "os.makedirs('deepfake-patch-audit/losses', exist_ok=True)\n",
    "os.makedirs('deepfake-patch-audit/scripts', exist_ok=True)\n",
    "os.makedirs('ECDD_Experimentation/Training/models', exist_ok=True)\n",
    "os.makedirs('ECDD_Experimentation/Training/training', exist_ok=True)\n",
    "print(\"Directory structure created.\")\n",
    "\n",
    "print(\"Writing Python scripts and configs...\")\n",
    "\n",
    "# --- Config Files --- \n",
    "base_yaml_content = \"\"\"\n",
    "model:\n",
    "  teacher:\n",
    "    architecture: \"LaDeDaResNet50\"\n",
    "  student:\n",
    "    architecture: \"TinyAttentionLaDeDa\"\n",
    "dataset:\n",
    "  resize_size: 256\n",
    "  num_workers: 2\n",
    "  pin_memory: true\n",
    "training:\n",
    "  weight_decay: 0.0001\n",
    "  distillation:\n",
    "    alpha_distill: 0.2\n",
    "    alpha_task: 0.8\n",
    "\"\"\"\n",
    "write_file('deepfake-patch-audit/config/base.yaml', base_yaml_content)\n",
    "\n",
    "# --- Model Files --- \n",
    "ladeda_resnet_content = \"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from typing import Tuple, Optional\n",
    "\n",
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, in_channels: int, hidden_dim: int = 128):\n",
    "        super().__init__()\n",
    "        self.attention_fc = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, hidden_dim, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(hidden_dim, 1, kernel_size=1)\n",
    "        )\n",
    "    def forward(self, features: torch.Tensor, patch_logits: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        attention_scores = self.attention_fc(features)\n",
    "        B, _, H, W = attention_scores.shape\n",
    "        attention_flat = attention_scores.view(B, -1)\n",
    "        attention_weights_flat = F.softmax(attention_flat, dim=1)\n",
    "        attention_weights = attention_weights_flat.view(B, 1, H, W)\n",
    "        patch_logits_flat = patch_logits.view(B, -1)\n",
    "        pooled_logit = (patch_logits_flat * attention_weights_flat).sum(dim=1, keepdim=True)\n",
    "        return pooled_logit, attention_weights\n",
    "\n",
    "class LaDeDaResNet50(nn.Module):\n",
    "    def __init__(self, pretrained: bool = True, freeze_layers: Optional[list] = None, num_classes: int = 1):\n",
    "        super().__init__()\n",
    "        base_model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2 if pretrained else None)\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        if pretrained:\n",
    "            with torch.no_grad():\n",
    "                self.conv1.weight.data = base_model.conv1.weight.data[:, :, 2:5, 2:5]\n",
    "        self.bn1 = base_model.bn1\n",
    "        self.relu = base_model.relu\n",
    "        self.layer1 = base_model.layer1\n",
    "        self.layer2 = base_model.layer2\n",
    "        self.layer3 = base_model.layer3\n",
    "        self.layer4 = base_model.layer4\n",
    "        self.patch_classifier = nn.Conv2d(2048, num_classes, kernel_size=1)\n",
    "        self.attention_pool = AttentionPooling(in_channels=2048)\n",
    "        if freeze_layers:\n",
    "            for name, param in self.named_parameters():\n",
    "                for layer_name in freeze_layers:\n",
    "                    if name.startswith(layer_name):\n",
    "                        param.requires_grad = False\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        features = self.layer4(x)\n",
    "        patch_logits = self.patch_classifier(features)\n",
    "        pooled_logit, attention_map = self.attention_pool(features, patch_logits)\n",
    "        return pooled_logit, patch_logits, attention_map\n",
    "\n",
    "def create_ladeda_model(pretrained: bool = True, freeze_layers: Optional[list] = None) -> LaDeDaResNet50:\n",
    "    return LaDeDaResNet50(pretrained=pretrained, freeze_layers=freeze_layers)\n",
    "\"\"\"\n",
    "write_file('ECDD_Experimentation/Training/models/ladeda_resnet.py', ladeda_resnet_content)\n",
    "\n",
    "tiny_attention_ladeda_content = \"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from ECDD_Experimentation.Training.models.ladeda_resnet import AttentionPooling\n",
    "\n",
    "class TinyAttentionLaDeDa(nn.Module):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "        self.patch_classifier = nn.Conv2d(32, num_classes, kernel_size=1)\n",
    "        # Attention pooling aligned with teacher, adapted for student's feature dimension\n",
    "        self.attention_pool = AttentionPooling(in_channels=32, hidden_dim=64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.features(x) \n",
    "        patch_logits = self.patch_classifier(features)\n",
    "        pooled_logit, attention_map = self.attention_pool(features, patch_logits)\n",
    "        return pooled_logit, patch_logits, attention_map\n",
    "\"\"\"\n",
    "write_file('deepfake-patch-audit/models/student/tiny_attention_ladeda.py', tiny_attention_ladeda_content)\n",
    "\n",
    "# --- Dataset and Loss Files ---\n",
    "base_dataset_content = \"\"\"\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from pathlib import Path\n",
    "\n",
    "class BaseDataset(Dataset):\n",
    "    def __init__(self, root_dir: str, resize_size: int = 256, normalize: bool = True):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.resize_size = resize_size\n",
    "        self.normalize = normalize\n",
    "        self.normalize_mean = np.array([0.485, 0.456, 0.406])\n",
    "        self.normalize_std = np.array([0.229, 0.224, 0.225])\n",
    "        self.samples = []\n",
    "        self._load_from_directory()\n",
    "\n",
    "    def _load_from_directory(self):\n",
    "        for label, class_name in enumerate(['real', 'fake']):\n",
    "            class_dir = self.root_dir / class_name\n",
    "            if class_dir.exists():\n",
    "                for img_path in sorted(class_dir.glob(f\"*.jpg\")):\n",
    "                    self.samples.append((str(img_path), label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            image = image.resize((self.resize_size, self.resize_size), Image.BICUBIC)\n",
    "            image = np.array(image, dtype=np.float32) / 255.0\n",
    "            if self.normalize:\n",
    "                image = (image - self.normalize_mean) / self.normalize_std\n",
    "            image = torch.from_numpy(image).permute(2, 0, 1)\n",
    "            return {\"image\": image, \"label\": torch.tensor(label, dtype=torch.long)}\n",
    "        except Exception:\n",
    "            # Return a blank image on error\n",
    "            return {\"image\": torch.zeros((3, self.resize_size, self.resize_size), dtype=torch.float32), \"label\": torch.tensor(label, dtype=torch.long)}\n",
    "\"\"\"\n",
    "write_file('deepfake-patch-audit/datasets/base_dataset.py', base_dataset_content)\n",
    "\n",
    "distillation_loss_content = \"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DistillationLoss(nn.Module):\n",
    "    def __init__(self, alpha_distill=0.2, alpha_task=0.8, temperature=4.0):\n",
    "        super().__init__()\n",
    "        self.alpha_distill = alpha_distill\n",
    "        self.alpha_task = alpha_task\n",
    "        self.temperature = temperature\n",
    "        self.bce_loss = nn.BCEWithLogitsLoss()\n",
    "        self.kl_loss = nn.KLDivLoss(reduction='batchmean')\n",
    "\n",
    "    def forward(self, student_pooled_logit, student_patches, teacher_patches, labels):\n",
    "        # Align patch grid sizes using adaptive pooling\n",
    "        student_patches_aligned = F.adaptive_avg_pool2d(student_patches, teacher_patches.shape[2:])\n",
    "        \n",
    "        # Distillation loss on patch logits\n",
    "        distill_loss = self.kl_loss(\n",
    "            F.log_softmax(student_patches_aligned / self.temperature, dim=1),\n",
    "            F.log_softmax(teacher_patches / self.temperature, dim=1)\n",
    "        ) * (self.temperature ** 2)\n",
    "        \n",
    "        # Task loss on the student's pooled output\n",
    "        task_loss = self.bce_loss(student_pooled_logit.squeeze(), labels.float())\n",
    "        \n",
    "        total_loss = self.alpha_distill * distill_loss + self.alpha_task * task_loss\n",
    "        return total_loss, distill_loss, task_loss\n",
    "\"\"\"\n",
    "write_file('deepfake-patch-audit/losses/distillation_loss.py', distillation_loss_content)\n",
    "\n",
    "# --- Training Scripts ---\n",
    "finetune_script_content = \"\"\"\n",
    "import os, sys, json, random, argparse\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image, ImageOps\n",
    "from tqdm import tqdm\n",
    "from ECDD_Experimentation.Training.models.ladeda_resnet import create_ladeda_model\n",
    "\n",
    "CONFIGS = {\n",
    "    \"finetune1\": {\"name\": \"finetune1_celeb_df\", \"dataset_path\": Path(\"ECDD_Experimentation/ECDD_Training_Data/processed/splits/finetune1\"), \"epochs\": 15, \"batch_size\": 16, \"lr\": 1e-4, \"freeze_layers\": [\"conv1\", \"layer1\"]},\n",
    "    \"finetune2\": {\"name\": \"finetune2_face_filtered\", \"dataset_path\": Path(\"ECDD_Experimentation/ECDD_Training_Data/processed/splits/finetune2\"), \"epochs\": 20, \"batch_size\": 8, \"lr\": 5e-5, \"freeze_layers\": [\"conv1\", \"layer1\"]}\n",
    "}\n",
    "TARGET_SIZE = (256, 256)\n",
    "IMAGENET_MEAN, IMAGENET_STD = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "\n",
    "class FinetuneDataset(Dataset):\n",
    "    def __init__(self, data_dir: Path, split: str = \"train\"):\n",
    "        self.data_dir = Path(data_dir) / split\n",
    "        self.images, self.labels = [], []\n",
    "        for label, class_name in enumerate(['real', 'fake']):\n",
    "            class_dir = self.data_dir / class_name\n",
    "            if class_dir.exists():\n",
    "                for f in class_dir.glob(\"*.jpg\"): self.images.append(f); self.labels.append(label)\n",
    "    def __len__(self): return len(self.images)\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.images[idx]).convert('RGB')\n",
    "        img = img.resize(TARGET_SIZE, Image.Resampling.LANCZOS)\n",
    "        img_array = (np.array(img).astype(np.float32) / 255.0 - IMAGENET_MEAN) / IMAGENET_STD\n",
    "        return torch.from_numpy(img_array).permute(2, 0, 1).float(), torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "\n",
    "def run_finetuning(config_name: str):\n",
    "    config = CONFIGS[config_name]\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    output_dir = Path(\"outputs\") / config_name\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    train_loader = DataLoader(FinetuneDataset(config['dataset_path'], \"train\"), batch_size=config['batch_size'], shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(FinetuneDataset(config['dataset_path'], \"val\"), batch_size=config['batch_size'], shuffle=False, num_workers=2)\n",
    "    model = create_ladeda_model(True, config['freeze_layers']).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=config['lr'])\n",
    "    for epoch in range(config['epochs']):\n",
    "        model.train()\n",
    "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            pooled_logit, _, _ = model(images)\n",
    "            loss = criterion(pooled_logit.squeeze(), labels)\n",
    "            optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
    "    torch.save(model.state_dict(), output_dir / 'finetuned_best.pth')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--config', type=str, choices=['finetune1', 'finetune2'], required=True)\n",
    "    args = parser.parse_args()\n",
    "    run_finetuning(args.config)\n",
    "\"\"\"\n",
    "write_file('ECDD_Experimentation/Training/training/finetune_script.py', finetune_script_content)\n",
    "\n",
    "train_teacher_content = \"\"\"\n",
    "import sys, yaml, torch, argparse\n",
    "from pathlib import Path\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from ECDD_Experimentation.Training.models.ladeda_resnet import create_ladeda_model\n",
    "from deepfake-patch-audit.datasets.base_dataset import BaseDataset\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description='Train Teacher with Attention Pooling')\n",
    "    parser.add_argument('--epochs', type=int, default=15, help='Training epochs')\n",
    "    parser.add_argument('--batch-size', type=int, default=32, help='Batch size')\n",
    "    parser.add_argument('--lr', type=float, default=1e-4, help='Learning rate')\n",
    "    parser.add_argument('--device', type=str, default='cuda', help='Device')\n",
    "    parser.add_argument('--output-dir', type=str, default='outputs/teacher_attention', help='Output directory')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    device = torch.device(args.device if torch.cuda.is_available() else 'cpu')\n",
    "    output_dir = Path(args.output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    model = create_ladeda_model(pretrained=True, freeze_layers=['conv1', 'layer1']).to(device)\n",
    "    \n",
    "    train_dataset = BaseDataset(root_dir=\"dataset/train\", resize_size=256)\n",
    "    val_dataset = BaseDataset(root_dir=\"dataset/val\", resize_size=256)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, num_workers=2)\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=args.lr)\n",
    "    \n",
    "    best_val_auc = 0.0\n",
    "    for epoch in range(args.epochs):\n",
    "        model.train()\n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "            images = batch[\"image\"].to(device)\n",
    "            labels = batch[\"label\"].to(device).float()\n",
    "            \n",
    "            pooled_logit, _, _ = model(images)\n",
    "            loss = criterion(pooled_logit.squeeze(), labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        model.eval()\n",
    "        all_preds, all_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                images = batch[\"image\"].to(device)\n",
    "                labels = batch[\"label\"].to(device).float()\n",
    "                pooled_logit, _, _ = model(images)\n",
    "                all_preds.append(torch.sigmoid(pooled_logit.squeeze()).cpu())\n",
    "                all_labels.append(labels.cpu())\n",
    "        \n",
    "        val_auc = roc_auc_score(torch.cat(all_labels), torch.cat(all_preds))\n",
    "        print(f\"Epoch {epoch+1}, Val AUC: {val_auc:.4f}\")\n",
    "        \n",
    "        if val_auc > best_val_auc:\n",
    "            best_val_auc = val_auc\n",
    "            torch.save(model.state_dict(), output_dir / \"teacher_best.pth\")\n",
    "            print(f\"Saved new best model with AUC: {best_val_auc:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\"\"\"\n",
    "write_file('deepfake-patch-audit/scripts/train_teacher.py', train_teacher_content)\n",
    "\n",
    "train_student_content = \"\"\"\n",
    "import sys, yaml, torch, argparse, random, numpy\n",
    "from pathlib import Path\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from ECDD_Experimentation.Training.models.ladeda_resnet import create_ladeda_model\n",
    "from deepfake-patch-audit.models.student.tiny_attention_ladeda import TinyAttentionLaDeDa\n",
    "from deepfake-patch-audit.datasets.base_dataset import BaseDataset\n",
    "from deepfake-patch-audit.losses.distillation_loss import DistillationLoss\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description='Train Student with Attention Distillation')\n",
    "    parser.add_argument('--epochs', type=int, default=30, help='Training epochs')\n",
    "    parser.add_argument('--batch-size', type=int, default=32, help='Batch size')\n",
    "    parser.add_argument('--lr', type=float, default=1e-3, help='Learning rate')\n",
    "    parser.add_argument('--device', type=str, default='cuda', help='Device')\n",
    "    parser.add_argument('--output-dir', type=str, default='outputs/student_attention', help='Output directory')\n",
    "    parser.add_argument('--teacher-weights', type=str, default='outputs/teacher_attention/teacher_best.pth', help='Path to teacher weights')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    device = torch.device(args.device if torch.cuda.is_available() else 'cpu')\n",
    "    output_dir = Path(args.output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Load Teacher (Attention-based LaDeDaResNet50)\n",
    "    teacher_model = create_ladeda_model(pretrained=False).to(device)\n",
    "    teacher_model.load_state_dict(torch.load(args.teacher_weights))\n",
    "    teacher_model.eval()\n",
    "    for param in teacher_model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Load Student (TinyAttentionLaDeDa)\n",
    "    student_model = TinyAttentionLaDeDa().to(device)\n",
    "    \n",
    "    train_dataset = BaseDataset(root_dir=\"dataset/train\", resize_size=256)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=2)\n",
    "    \n",
    "    criterion = DistillationLoss()\n",
    "    optimizer = optim.Adam(student_model.parameters(), lr=args.lr)\n",
    "    \n",
    "    for epoch in range(args.epochs):\n",
    "        student_model.train()\n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "            images = batch[\"image\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "            \n",
    "            # Get outputs from both models\n",
    "            student_pooled_logit, student_patches, _ = student_model(images)\n",
    "            with torch.no_grad():\n",
    "                _, teacher_patches, _ = teacher_model(images)\n",
    "            \n",
    "            loss, _, _ = criterion(student_pooled_logit, student_patches, teacher_patches, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    torch.save(student_model.state_dict(), output_dir / \"student_best.pth\")\n",
    "    print(f\"Saved final student model to {output_dir / 'student_best.pth'}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\"\"\"\n",
    "write_file('deepfake-patch-audit/scripts/train_student_two_stage.py', train_student_content)\n",
    "\n",
    "print(\"All files written successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data and Pretrained Weights\n",
    "\n",
    "For this notebook to work, you must upload your data with the following directory structure:\n",
    "\n",
    "```\n",
    "./dataset/\n",
    "└── train/\n",
    "    ├── real/\n",
    "    │   ├── 0001.jpg\n",
    "    │   └── ...\n",
    "    └── fake/\n",
    "        ├── 0001.jpg\n",
    "        └── ...\n",
    "└── val/\n",
    "    ├── real/\n",
    "    │   └── ...\n",
    "    └── fake/\n",
    "        └── ...\n",
    "\n",
    "./ECDD_Experimentation/ECDD_Training_Data/processed/splits/\n",
    "└── finetune1/\n",
    "    ├── train/\n",
    "    │   ├── real/\n",
    "    │   └── fake/\n",
    "    └── val/\n",
    "        └── ...\n",
    "└── finetune2/\n",
    "    └── ...\n",
    "```\n",
    "\n",
    "You can zip these folders, upload the zip file to the Colab environment, and then run the following cell to unzip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: !unzip data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training Commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Train the Teacher Model\n",
    "\n",
    "This fine-tunes a pretrained `LaDeDaResNet50` on your custom dataset. The best model based on validation AUC will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python deepfake-patch-audit/scripts/train_teacher.py --epochs 10 --batch-size 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Train the Student Model\n",
    "\n",
    "This trains the new `TinyAttentionLaDeDa` student model to mimic the teacher you just trained, using the patch-distillation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python deepfake-patch-audit/scripts/train_student_two_stage.py --epochs 20 --batch-size 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Run Finetuning (ECDD Experimentation)\n",
    "\n",
    "This runs the finetuning script from the `ECDD_Experimentation` folder, which also uses the attention-based `LaDeDaResNet50` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ECDD_Experimentation/Training/training/finetune_script.py --config finetune1"
   ]
  }
 ]
}
