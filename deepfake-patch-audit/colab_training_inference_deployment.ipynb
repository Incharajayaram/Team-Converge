{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Deepfake Detection: End-to-End Training, Inference & Deployment\n",
        "\n",
        "This notebook provides a complete pipeline for:\n",
        "1. **Training**: Single-stage and two-stage fine-tuning of Tiny-LaDeDa student model\n",
        "2. **Inference**: Patch-level predictions with heatmap visualization\n",
        "3. **Deployment**: Model quantization, ONNX export, and TFLite conversion\n",
        "\n",
        "For Google Colab:\n",
        "1. Mount your Google Drive\n",
        "2. Place dataset in: /content/drive/MyDrive/deepfake-patch-audit/data/\n",
        "3. Run cells sequentially"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU availability\n",
        "import torch\n",
        "print(f\"CUDA Available: {togrch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
        "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "packages = [\n",
        "    'torch',\n",
        "    'torchvision',\n",
        "    'onnx',\n",
        "    'onnxruntime',\n",
        "    'scikit-learn',\n",
        "    'pillow',\n",
        "    'tqdm',\n",
        "    'pandas',\n",
        "    'numpy',\n",
        "    'tensorflow',\n",
        "]\n",
        "\n",
        "for package in packages:\n",
        "    try:\n",
        "        __import__(package)\n",
        "        print(f\"✓ {package} already installed\")\n",
        "    except ImportError:\n",
        "        print(f\"Installing {package}...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
        "        print(f\"✓ {package} installed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Check if running in Colab\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "    print(\"✓ Running in Google Colab\")\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    print(\"✓ Running locally\")\n",
        "\n",
        "# Mount Google Drive if in Colab\n",
        "if IN_COLAB:\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    PROJECT_ROOT = Path('/content/drive/MyDrive/deepfake-patch-audit')\n",
        "    print(f\"Project root: {PROJECT_ROOT}\")\n",
        "else:\n",
        "    PROJECT_ROOT = Path('/home/incharaj/Team-Converge/deepfake-patch-audit')\n",
        "\n",
        "# Add project to path\n",
        "sys.path.insert(0, str(PROJECT_ROOT))\n",
        "os.chdir(PROJECT_ROOT)\n",
        "\n",
        "print(f\"Working directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Device configuration\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "# Set random seeds\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)\n",
        "\n",
        "print(\"✓ Configuration complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BaseDataset(Dataset):\n",
        "    '''Base dataset class for deepfake detection.'''\n",
        "    \n",
        "    def __init__(self, root_dir, split='train', image_format='jpg',\n",
        "                 resize_size=256, normalize=True, normalize_mean=None,\n",
        "                 normalize_std=None, split_file=None):\n",
        "        self.root_dir = Path(root_dir)\n",
        "        self.split = split\n",
        "        self.image_format = image_format\n",
        "        self.resize_size = resize_size\n",
        "        self.normalize = normalize\n",
        "        self.split_file = split_file\n",
        "        \n",
        "        if normalize_mean is None:\n",
        "            self.normalize_mean = np.array([0.485, 0.456, 0.406])\n",
        "        else:\n",
        "            self.normalize_mean = np.array(normalize_mean)\n",
        "        \n",
        "        if normalize_std is None:\n",
        "            self.normalize_std = np.array([0.229, 0.224, 0.225])\n",
        "        else:\n",
        "            self.normalize_std = np.array(normalize_std)\n",
        "        \n",
        "        self.samples = []\n",
        "        self._load_samples()\n",
        "    \n",
        "    def _load_samples(self):\n",
        "        if self.split_file:\n",
        "            self._load_from_csv()\n",
        "        else:\n",
        "            self._load_from_directory()\n",
        "    \n",
        "    def _load_from_csv(self):\n",
        "        split_path = Path(self.split_file)\n",
        "        if not split_path.exists():\n",
        "            raise FileNotFoundError(f\"Split file not found: {split_path}\")\n",
        "        df = pd.read_csv(split_path)\n",
        "        for _, row in df.iterrows():\n",
        "            img_path = row['path']\n",
        "            label = int(row['label'])\n",
        "            if Path(img_path).exists():\n",
        "                self.samples.append((img_path, label))\n",
        "        print(f\"✓ Loaded {len(self.samples)} samples from {split_path}\")\n",
        "    \n",
        "    def _load_from_directory(self):\n",
        "        real_dir = self.root_dir / \"real\"\n",
        "        if real_dir.exists():\n",
        "            for img_path in sorted(real_dir.glob(f\"*.{self.image_format}\")):\n",
        "                self.samples.append((str(img_path), 0))\n",
        "        \n",
        "        fake_dir = self.root_dir / \"fake\"\n",
        "        if fake_dir.exists():\n",
        "            for img_path in sorted(fake_dir.glob(f\"*.{self.image_format}\")):\n",
        "                self.samples.append((str(img_path), 1))\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.samples[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        image = image.resize((self.resize_size, self.resize_size), Image.BICUBIC)\n",
        "        image = np.array(image, dtype=np.float32) / 255.0\n",
        "        \n",
        "        if self.normalize:\n",
        "            image = (image - self.normalize_mean) / self.normalize_std\n",
        "        \n",
        "        image = torch.from_numpy(image).permute(2, 0, 1)\n",
        "        return {\"image\": image, \"label\": torch.tensor(label, dtype=torch.long)}\n",
        "\n",
        "print(\"✓ BaseDataset class defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class TinyLaDeDaModel(nn.Module):\n",
        "    '''Ultra-lightweight student model (1,297 parameters).'''\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.register_buffer('grad_filter', torch.tensor(\n",
        "            [[0, 0, 0], [0, -2, 1], [0, 1, 0]], dtype=torch.float32\n",
        "        ).unsqueeze(0).unsqueeze(0))\n",
        "        \n",
        "        self.conv = nn.Conv2d(3, 8, kernel_size=1, stride=1, padding=0, bias=True)\n",
        "        self.fc = nn.Linear(8, 1, bias=True)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x_preprocessed = []\n",
        "        for i in range(3):\n",
        "            channel = x[:, i:i+1, :, :]\n",
        "            grad = F.conv2d(channel, self.grad_filter, padding=1)\n",
        "            x_preprocessed.append(grad)\n",
        "        x_grad = torch.cat(x_preprocessed, dim=1)\n",
        "        \n",
        "        x_conv = self.conv(x_grad)\n",
        "        x_pool = F.avg_pool2d(x_conv, kernel_size=2, stride=2)\n",
        "        \n",
        "        b, c, h, w = x_pool.shape\n",
        "        x_reshape = x_pool.permute(0, 2, 3, 1)\n",
        "        x_logits = self.fc(x_reshape)\n",
        "        x_logits = x_logits.permute(0, 3, 1, 2)\n",
        "        \n",
        "        x_out = F.interpolate(x_logits, size=(126, 126), mode='bilinear', align_corners=False)\n",
        "        return x_out\n",
        "\n",
        "class TinyLaDeDa(nn.Module):\n",
        "    '''Wrapper for Tiny-LaDeDa student model.'''\n",
        "    \n",
        "    def __init__(self, pretrained=False, pretrained_path=None):\n",
        "        super().__init__()\n",
        "        self.model = TinyLaDeDaModel()\n",
        "        if pretrained and pretrained_path and Path(pretrained_path).exists():\n",
        "            state_dict = torch.load(pretrained_path, map_location='cpu')\n",
        "            self.model.load_state_dict(state_dict)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "    \n",
        "    def count_parameters(self):\n",
        "        return sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
        "\n",
        "test_model = TinyLaDeDa()\n",
        "print(f\"✓ TinyLaDeDa model defined ({test_model.count_parameters()} parameters)\")\n",
        "del test_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TopKLogitPooling(nn.Module):\n",
        "    '''Top-K logit pooling for spatial patch-logit maps.'''\n",
        "    \n",
        "    def __init__(self, k_percent=0.1):\n",
        "        super().__init__()\n",
        "        self.k_percent = k_percent\n",
        "    \n",
        "    def forward(self, logits):\n",
        "        b = logits.size(0)\n",
        "        flat = logits.view(b, -1)\n",
        "        k = max(1, int(flat.size(1) * self.k_percent))\n",
        "        top_k_vals = torch.topk(flat, k, dim=1)[0]\n",
        "        image_logit = top_k_vals.mean(dim=1, keepdim=True)\n",
        "        return image_logit\n",
        "\n",
        "class PatchDistillationLoss(nn.Module):\n",
        "    '''Combined loss: Patch-level MSE + Image-level BCE.'''\n",
        "    \n",
        "    def __init__(self, alpha=0.5):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.mse_loss = nn.MSELoss()\n",
        "        self.bce_loss = nn.BCEWithLogitsLoss()\n",
        "    \n",
        "    def forward(self, student_patches, teacher_patches, student_image_logit, labels):\n",
        "        teacher_resized = F.interpolate(\n",
        "            teacher_patches, size=student_patches.shape[-2:], \n",
        "            mode='bilinear', align_corners=False\n",
        "        )\n",
        "        distill_loss = self.mse_loss(student_patches, teacher_resized)\n",
        "        task_loss = self.bce_loss(student_image_logit.squeeze(1), labels.float())\n",
        "        total_loss = self.alpha * distill_loss + (1 - self.alpha) * task_loss\n",
        "        return total_loss, distill_loss, task_loss\n",
        "\n",
        "print(\"✓ TopKLogitPooling and PatchDistillationLoss defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PatchStudentTrainer:\n",
        "    '''Train student model with patch-level knowledge distillation.'''\n",
        "    \n",
        "    def __init__(self, student_model, teacher_model, train_loader, val_loader,\n",
        "                 criterion, pooling, device='cuda', lr=0.001, weight_decay=1e-4):\n",
        "        self.student_model = student_model.to(device)\n",
        "        self.teacher_model = teacher_model.to(device)\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.criterion = criterion.to(device)\n",
        "        self.pooling = pooling.to(device)\n",
        "        self.device = device\n",
        "        \n",
        "        self.teacher_model.eval()\n",
        "        for param in self.teacher_model.parameters():\n",
        "            param.requires_grad = False\n",
        "        \n",
        "        self.optimizer = optim.Adam(self.student_model.parameters(), \n",
        "                                   lr=lr, weight_decay=weight_decay)\n",
        "        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
        "            self.optimizer, T_max=50, eta_min=1e-6)\n",
        "        \n",
        "        self.history = {\n",
        "            'train_loss': [], 'val_loss': [], 'val_acc': [], 'val_auc': []\n",
        "        }\n",
        "    \n",
        "    def train_epoch(self):\n",
        "        self.student_model.train()\n",
        "        total_loss = 0.0\n",
        "        pbar = tqdm(self.train_loader, desc='Training', leave=False)\n",
        "        \n",
        "        for batch in pbar:\n",
        "            images = batch['image'].to(self.device)\n",
        "            labels = batch['label'].to(self.device)\n",
        "            \n",
        "            student_patches = self.student_model(images)\n",
        "            student_image_logit = self.pooling(student_patches)\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                teacher_patches = self.teacher_model(images)\n",
        "            \n",
        "            loss, _, _ = self.criterion(student_patches, teacher_patches, \n",
        "                                       student_image_logit, labels)\n",
        "            \n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(self.student_model.parameters(), max_norm=1.0)\n",
        "            self.optimizer.step()\n",
        "            \n",
        "            total_loss += loss.item()\n",
        "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
        "        \n",
        "        avg_loss = total_loss / len(self.train_loader)\n",
        "        self.history['train_loss'].append(avg_loss)\n",
        "        return avg_loss\n",
        "    \n",
        "    def validate(self):\n",
        "        self.student_model.eval()\n",
        "        total_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        all_preds, all_targets = [], []\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for batch in self.val_loader:\n",
        "                images = batch['image'].to(self.device)\n",
        "                labels = batch['label'].to(self.device)\n",
        "                \n",
        "                student_patches = self.student_model(images)\n",
        "                student_image_logit = self.pooling(student_patches)\n",
        "                teacher_patches = self.teacher_model(images)\n",
        "                \n",
        "                loss, _, _ = self.criterion(student_patches, teacher_patches, \n",
        "                                           student_image_logit, labels)\n",
        "                \n",
        "                total_loss += loss.item()\n",
        "                predicted = (student_image_logit.squeeze(1) > 0.0).long()\n",
        "                correct += (predicted == labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "                \n",
        "                all_preds.append(torch.sigmoid(student_image_logit.squeeze(1)).cpu())\n",
        "                all_targets.append(labels.cpu())\n",
        "        \n",
        "        avg_loss = total_loss / len(self.val_loader)\n",
        "        accuracy = correct / total\n",
        "        \n",
        "        try:\n",
        "            all_preds = torch.cat(all_preds).numpy()\n",
        "            all_targets = torch.cat(all_targets).numpy()\n",
        "            auc = roc_auc_score(all_targets, all_preds)\n",
        "        except:\n",
        "            auc = 0.0\n",
        "        \n",
        "        self.history['val_loss'].append(avg_loss)\n",
        "        self.history['val_acc'].append(accuracy)\n",
        "        self.history['val_auc'].append(auc)\n",
        "        return avg_loss, accuracy, auc\n",
        "    \n",
        "    def train(self, epochs, checkpoint_dir='outputs/checkpoints'):\n",
        "        checkpoint_dir = Path(checkpoint_dir)\n",
        "        checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
        "        best_val_auc = 0.0\n",
        "        \n",
        "        print('\\n' + '='*80)\n",
        "        print('PATCH-LEVEL DISTILLATION TRAINING')\n",
        "        print('='*80)\n",
        "        \n",
        "        for epoch in range(epochs):\n",
        "            train_loss = self.train_epoch()\n",
        "            val_loss, val_acc, val_auc = self.validate()\n",
        "            self.scheduler.step()\n",
        "            \n",
        "            print(f'Epoch {epoch+1}/{epochs} | Loss: {train_loss:.4f} | Val AUC: {val_auc:.4f}')\n",
        "            \n",
        "            if val_auc > best_val_auc:\n",
        "                best_val_auc = val_auc\n",
        "                torch.save(self.student_model.state_dict(), \n",
        "                          checkpoint_dir / 'student_best.pt')\n",
        "        \n",
        "        torch.save(self.student_model.state_dict(), \n",
        "                  checkpoint_dir / 'student_final.pt')\n",
        "        print(f'\\n✓ Training complete. Final model saved.')\n",
        "        return self.history\n",
        "\n",
        "print(\"✓ PatchStudentTrainer class defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TwoStagePatchStudentTrainer:\n",
        "    '''Two-stage fine-tuning with progressive unfreezing.'''\n",
        "    \n",
        "    def __init__(self, student_model, teacher_model, train_loader, val_loader,\n",
        "                 criterion, pooling, device='cuda', stage1_lr=0.001, \n",
        "                 stage2_lr=0.0001, weight_decay=1e-4):\n",
        "        self.student_model = student_model.to(device)\n",
        "        self.teacher_model = teacher_model.to(device)\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.criterion = criterion.to(device)\n",
        "        self.pooling = pooling.to(device)\n",
        "        self.device = device\n",
        "        self.stage1_lr = stage1_lr\n",
        "        self.stage2_lr = stage2_lr\n",
        "        self.weight_decay = weight_decay\n",
        "        \n",
        "        self.teacher_model.eval()\n",
        "        for param in self.teacher_model.parameters():\n",
        "            param.requires_grad = False\n",
        "        \n",
        "        self.history = {'train_loss': [], 'val_loss': [], 'val_auc': []}\n",
        "        self.optimizer = None\n",
        "        self.scheduler = None\n",
        "    \n",
        "    def _freeze_backbone(self):\n",
        "        model = (self.student_model.model if hasattr(self.student_model, 'model') \n",
        "                else self.student_model)\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "        if hasattr(model, 'fc'):\n",
        "            for param in model.fc.parameters():\n",
        "                param.requires_grad = True\n",
        "    \n",
        "    def _unfreeze_layer1(self):\n",
        "        model = (self.student_model.model if hasattr(self.student_model, 'model') \n",
        "                else self.student_model)\n",
        "        if hasattr(model, 'conv'):\n",
        "            for param in model.conv.parameters():\n",
        "                param.requires_grad = True\n",
        "    \n",
        "    def _setup_stage1_optimizer(self):\n",
        "        model = (self.student_model.model if hasattr(self.student_model, 'model') \n",
        "                else self.student_model)\n",
        "        trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
        "        self.optimizer = optim.Adam(trainable_params, lr=self.stage1_lr, \n",
        "                                   weight_decay=self.weight_decay)\n",
        "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            self.optimizer, mode='max', factor=0.5, patience=2)\n",
        "    \n",
        "    def _setup_stage2_optimizer(self):\n",
        "        model = (self.student_model.model if hasattr(self.student_model, 'model') \n",
        "                else self.student_model)\n",
        "        trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
        "        self.optimizer = optim.Adam(trainable_params, lr=self.stage2_lr, \n",
        "                                   weight_decay=self.weight_decay)\n",
        "        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
        "            self.optimizer, T_max=20, eta_min=1e-6)\n",
        "    \n",
        "    def train_epoch(self, stage):\n",
        "        self.student_model.train()\n",
        "        total_loss = 0.0\n",
        "        pbar = tqdm(self.train_loader, desc=f'Stage {stage} Training', leave=False)\n",
        "        \n",
        "        for batch in pbar:\n",
        "            images = batch['image'].to(self.device)\n",
        "            labels = batch['label'].to(self.device)\n",
        "            \n",
        "            student_patches = self.student_model(images)\n",
        "            student_image_logit = self.pooling(student_patches)\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                teacher_patches = self.teacher_model(images)\n",
        "            \n",
        "            loss, _, _ = self.criterion(student_patches, teacher_patches, \n",
        "                                       student_image_logit, labels)\n",
        "            \n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(self.student_model.parameters(), max_norm=1.0)\n",
        "            self.optimizer.step()\n",
        "            \n",
        "            total_loss += loss.item()\n",
        "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
        "        \n",
        "        avg_loss = total_loss / len(self.train_loader)\n",
        "        self.history['train_loss'].append(avg_loss)\n",
        "        return avg_loss\n",
        "    \n",
        "    def validate(self):\n",
        "        self.student_model.eval()\n",
        "        total_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        all_preds, all_targets = [], []\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for batch in self.val_loader:\n",
        "                images = batch['image'].to(self.device)\n",
        "                labels = batch['label'].to(self.device)\n",
        "                \n",
        "                student_patches = self.student_model(images)\n",
        "                student_image_logit = self.pooling(student_patches)\n",
        "                teacher_patches = self.teacher_model(images)\n",
        "                \n",
        "                loss, _, _ = self.criterion(student_patches, teacher_patches, \n",
        "                                           student_image_logit, labels)\n",
        "                \n",
        "                total_loss += loss.item()\n",
        "                predicted = (student_image_logit.squeeze(1) > 0.0).long()\n",
        "                correct += (predicted == labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "                \n",
        "                all_preds.append(torch.sigmoid(student_image_logit.squeeze(1)).cpu())\n",
        "                all_targets.append(labels.cpu())\n",
        "        \n",
        "        avg_loss = total_loss / len(self.val_loader)\n",
        "        accuracy = correct / total\n",
        "        \n",
        "        try:\n",
        "            auc = roc_auc_score(torch.cat(all_targets).numpy(), torch.cat(all_preds).numpy())\n",
        "        except:\n",
        "            auc = 0.0\n",
        "        \n",
        "        self.history['val_loss'].append(avg_loss)\n",
        "        self.history['val_auc'].append(auc)\n",
        "        return avg_loss, accuracy, auc\n",
        "    \n",
        "    def train(self, epochs_s1=5, epochs_s2=20, checkpoint_dir='outputs/checkpoints_two_stage'):\n",
        "        checkpoint_dir = Path(checkpoint_dir)\n",
        "        checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
        "        best_val_auc = 0.0\n",
        "        \n",
        "        print('\\n' + '='*80)\n",
        "        print('TWO-STAGE FINE-TUNING')\n",
        "        print('='*80)\n",
        "        \n",
        "        print('\\n*** STAGE 1: Freeze Backbone, Train Classifier ***')\n",
        "        self._freeze_backbone()\n",
        "        self._setup_stage1_optimizer()\n",
        "        \n",
        "        for epoch in range(epochs_s1):\n",
        "            train_loss = self.train_epoch(stage=1)\n",
        "            val_loss, val_acc, val_auc = self.validate()\n",
        "            lr = self.optimizer.param_groups[0]['lr']\n",
        "            print(f'S1 Epoch {epoch+1}/{epochs_s1} | Loss: {train_loss:.4f} | AUC: {val_auc:.4f}')\n",
        "            self.scheduler.step(val_auc)\n",
        "            \n",
        "            if val_auc > best_val_auc:\n",
        "                best_val_auc = val_auc\n",
        "                torch.save(self.student_model.state_dict(), \n",
        "                          checkpoint_dir / 'student_best.pt')\n",
        "        \n",
        "        print('\\n*** STAGE 2: Unfreeze Last Layers, Fine-tune ***')\n",
        "        self._unfreeze_layer1()\n",
        "        self._setup_stage2_optimizer()\n",
        "        \n",
        "        for epoch in range(epochs_s2):\n",
        "            train_loss = self.train_epoch(stage=2)\n",
        "            val_loss, val_acc, val_auc = self.validate()\n",
        "            print(f'S2 Epoch {epoch+1}/{epochs_s2} | Loss: {train_loss:.4f} | AUC: {val_auc:.4f}')\n",
        "            self.scheduler.step()\n",
        "            \n",
        "            if val_auc > best_val_auc:\n",
        "                best_val_auc = val_auc\n",
        "                torch.save(self.student_model.state_dict(), \n",
        "                          checkpoint_dir / 'student_best.pt')\n",
        "        \n",
        "        torch.save(self.student_model.state_dict(), \n",
        "                  checkpoint_dir / 'student_final.pt')\n",
        "        print(f'\\n✓ Two-stage training complete.')\n",
        "        return self.history\n",
        "\n",
        "print(\"✓ TwoStagePatchStudentTrainer class defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class InferencePipeline:\n",
        "    '''Complete inference pipeline with patch-level predictions and heatmaps.'''\n",
        "    \n",
        "    def __init__(self, model, pooling, device='cuda', image_size=256,\n",
        "                 normalize_mean=None, normalize_std=None):\n",
        "        self.model = model.to(device)\n",
        "        self.model.eval()\n",
        "        self.pooling = pooling.to(device) if pooling else None\n",
        "        self.device = device\n",
        "        self.image_size = image_size\n",
        "        \n",
        "        if normalize_mean is None:\n",
        "            self.normalize_mean = np.array([0.485, 0.456, 0.406])\n",
        "        else:\n",
        "            self.normalize_mean = np.array(normalize_mean)\n",
        "        \n",
        "        if normalize_std is None:\n",
        "            self.normalize_std = np.array([0.229, 0.224, 0.225])\n",
        "        else:\n",
        "            self.normalize_std = np.array(normalize_std)\n",
        "    \n",
        "    def _preprocess_image(self, image):\n",
        "        if isinstance(image, str):\n",
        "            image = Image.open(image).convert('RGB')\n",
        "        elif not isinstance(image, Image.Image):\n",
        "            image = Image.fromarray((image * 255).astype(np.uint8))\n",
        "        \n",
        "        image = image.resize((self.image_size, self.image_size), Image.BICUBIC)\n",
        "        image = np.array(image, dtype=np.float32) / 255.0\n",
        "        image = (image - self.normalize_mean) / self.normalize_std\n",
        "        image = torch.from_numpy(image).permute(2, 0, 1).unsqueeze(0)\n",
        "        return image\n",
        "    \n",
        "    def predict(self, image):\n",
        "        image_tensor = self._preprocess_image(image).to(self.device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            patch_logits = self.model(image_tensor)\n",
        "            if self.pooling:\n",
        "                image_logit = self.pooling(patch_logits)\n",
        "            else:\n",
        "                image_logit = patch_logits.mean(dim=[2, 3], keepdim=True)\n",
        "            \n",
        "            fake_prob = torch.sigmoid(image_logit).item()\n",
        "            patch_heatmap = torch.sigmoid(patch_logits).squeeze(1)\n",
        "        \n",
        "        return {\n",
        "            'patch_logits': patch_logits.cpu().numpy(),\n",
        "            'patch_heatmap': patch_heatmap.cpu().numpy(),\n",
        "            'fake_prob': fake_prob,\n",
        "            'real_prob': 1.0 - fake_prob,\n",
        "            'prediction': 'FAKE' if fake_prob > 0.5 else 'REAL',\n",
        "        }\n",
        "    \n",
        "    def predict_batch(self, images_list):\n",
        "        batch_images = []\n",
        "        for img in images_list:\n",
        "            img_tensor = self._preprocess_image(img)\n",
        "            batch_images.append(img_tensor)\n",
        "        \n",
        "        batch_tensor = torch.cat(batch_images, dim=0).to(self.device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            patch_logits = self.model(batch_tensor)\n",
        "            if self.pooling:\n",
        "                image_logits = self.pooling(patch_logits)\n",
        "            else:\n",
        "                image_logits = patch_logits.mean(dim=[2, 3], keepdim=True)\n",
        "            \n",
        "            fake_probs = torch.sigmoid(image_logits).squeeze(1).cpu().numpy()\n",
        "        \n",
        "        results = []\n",
        "        for prob in fake_probs:\n",
        "            results.append({\n",
        "                'fake_prob': float(prob),\n",
        "                'real_prob': 1.0 - float(prob),\n",
        "                'prediction': 'FAKE' if prob > 0.5 else 'REAL',\n",
        "            })\n",
        "        return results\n",
        "    \n",
        "    def visualize_heatmap(self, image, result, figsize=(15, 5)):\n",
        "        if isinstance(image, str):\n",
        "            image = Image.open(image).convert('RGB')\n",
        "        image = np.array(image.resize((256, 256), Image.BICUBIC), dtype=np.float32) / 255.0\n",
        "        heatmap = result['patch_heatmap'][0]\n",
        "        \n",
        "        fig, axes = plt.subplots(1, 3, figsize=figsize)\n",
        "        axes[0].imshow(image)\n",
        "        axes[0].set_title('Original Image')\n",
        "        axes[0].axis('off')\n",
        "        \n",
        "        im1 = axes[1].imshow(heatmap, cmap='RdYlGn_r', vmin=0, vmax=1)\n",
        "        axes[1].set_title('Fake Probability Heatmap')\n",
        "        axes[1].axis('off')\n",
        "        plt.colorbar(im1, ax=axes[1])\n",
        "        \n",
        "        heatmap_resized = np.array(Image.fromarray((heatmap * 255).astype(np.uint8)).resize(\n",
        "            (256, 256), Image.BICUBIC)) / 255.0\n",
        "        axes[2].imshow(image)\n",
        "        im2 = axes[2].imshow(heatmap_resized, cmap='RdYlGn_r', vmin=0, vmax=1, alpha=0.5)\n",
        "        pred_text = f\"Pred: {result['prediction']}, Prob: {result['fake_prob']:.3f}\"\n",
        "        axes[2].set_title(f'Overlay ({pred_text})')\n",
        "        axes[2].axis('off')\n",
        "        plt.colorbar(im2, ax=axes[2])\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        return fig\n",
        "\n",
        "print(\"✓ InferencePipeline class defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ImprovedDynamicRangeQuantizer:\n",
        "    '''Dynamic range quantization with per-channel and outlier clipping.'''\n",
        "    \n",
        "    def __init__(self, bits=8, symmetric=False, per_channel=True,\n",
        "                 clip_outliers=True, clip_percentile=99.9):\n",
        "        self.bits = bits\n",
        "        self.symmetric = symmetric\n",
        "        self.per_channel = per_channel\n",
        "        self.clip_outliers = clip_outliers\n",
        "        self.clip_percentile = clip_percentile\n",
        "        \n",
        "        if bits == 8:\n",
        "            self.qmin, self.qmax = -128, 127\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported bit width: {bits}\")\n",
        "    \n",
        "    def _compute_quant_params_per_tensor(self, X):\n",
        "        if self.clip_outliers:\n",
        "            percentile_val = np.percentile(np.abs(X), self.clip_percentile)\n",
        "            X_clipped = np.clip(X, -percentile_val, percentile_val)\n",
        "        else:\n",
        "            X_clipped = X\n",
        "        \n",
        "        x_min = X_clipped.min()\n",
        "        x_max = X_clipped.max()\n",
        "        \n",
        "        if x_max == x_min:\n",
        "            scale = 1e-8\n",
        "        else:\n",
        "            if self.symmetric:\n",
        "                abs_max = max(abs(x_min), abs(x_max))\n",
        "                scale = (2 * abs_max) / (self.qmax - self.qmin)\n",
        "            else:\n",
        "                scale = (x_max - x_min) / (self.qmax - self.qmin)\n",
        "        \n",
        "        if self.symmetric:\n",
        "            zero_point = 0\n",
        "        else:\n",
        "            zero_point_real = self.qmin - x_min / scale\n",
        "            zero_point = int(round(zero_point_real))\n",
        "            zero_point = np.clip(zero_point, self.qmin, self.qmax)\n",
        "        \n",
        "        return scale, zero_point\n",
        "    \n",
        "    def _compute_quant_params_per_channel(self, tensor):\n",
        "        out_channels = tensor.shape[0]\n",
        "        scales, zero_points = [], []\n",
        "        \n",
        "        for ch in range(out_channels):\n",
        "            channel_data = tensor[ch].detach().cpu().numpy().flatten()\n",
        "            scale, zp = self._compute_quant_params_per_tensor(channel_data)\n",
        "            scales.append(scale)\n",
        "            zero_points.append(zp)\n",
        "        \n",
        "        return np.array(scales), np.array(zero_points)\n",
        "    \n",
        "    def quantize_model(self, model):\n",
        "        quant_params = {}\n",
        "        model.eval()\n",
        "        \n",
        "        for name, module in model.named_modules():\n",
        "            if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
        "                if hasattr(module, 'weight'):\n",
        "                    weight = module.weight.data\n",
        "                    if self.per_channel and weight.dim() > 1:\n",
        "                        scales, zps = self._compute_quant_params_per_channel(weight)\n",
        "                    else:\n",
        "                        scale, zp = self._compute_quant_params_per_tensor(\n",
        "                            weight.cpu().numpy().flatten())\n",
        "                        scales, zps = np.array([scale]), np.array([zp])\n",
        "                    \n",
        "                    quant_params[name] = {\n",
        "                        'scales': scales, 'zero_points': zps, 'shape': weight.shape\n",
        "                    }\n",
        "        \n",
        "        return model, quant_params\n",
        "    \n",
        "    def get_quantization_report(self, quant_params):\n",
        "        report = '\\n' + '='*80 + '\\n' + 'QUANTIZATION REPORT\\n' + '='*80 + '\\n'\n",
        "        report += f'Bits: {self.bits}\\n'\n",
        "        report += f'Mode: {\"Symmetric\" if self.symmetric else \"Asymmetric\"}\\n'\n",
        "        report += f'Per-Channel: {self.per_channel}\\n'\n",
        "        report += f'Outlier Clipping: {self.clip_outliers} ({self.clip_percentile}th percentile)\\n'\n",
        "        report += f'Total layers quantized: {len(quant_params)}\\n'\n",
        "        return report\n",
        "\n",
        "print(\"✓ ImprovedDynamicRangeQuantizer class defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_sample_data_loaders(dataset_root, batch_size=16, num_workers=0):\n",
        "    '''Create train/val dataloaders.'''\n",
        "    try:\n",
        "        train_dataset = BaseDataset(\n",
        "            root_dir=f\"{dataset_root}/train\",\n",
        "            split='train',\n",
        "            image_format='jpg',\n",
        "            resize_size=256,\n",
        "        )\n",
        "        print(f\"✓ Loaded {len(train_dataset)} training samples\")\n",
        "        \n",
        "        val_dataset = BaseDataset(\n",
        "            root_dir=f\"{dataset_root}/val\",\n",
        "            split='val',\n",
        "            image_format='jpg',\n",
        "            resize_size=256,\n",
        "        )\n",
        "        print(f\"✓ Loaded {len(val_dataset)} validation samples\")\n",
        "        \n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, \n",
        "                                 shuffle=True, num_workers=num_workers)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=batch_size, \n",
        "                               shuffle=False, num_workers=num_workers)\n",
        "        \n",
        "        return train_loader, val_loader\n",
        "    except Exception as e:\n",
        "        print(f\"⚠ Failed to load dataset: {e}\")\n",
        "        print(\"Expected structure: dataset_root/train/{real,fake}/ and /val/{real,fake}/\")\n",
        "        return None, None\n",
        "\n",
        "def initialize_training_pipeline(device=DEVICE):\n",
        "    '''Initialize student, teacher, pooling, and loss.'''\n",
        "    student_model = TinyLaDeDa(pretrained=False)\n",
        "    print(f\"✓ Student model initialized ({student_model.count_parameters()} parameters)\")\n",
        "    \n",
        "    teacher_model = TinyLaDeDa(pretrained=False)\n",
        "    print(f\"✓ Teacher model initialized\")\n",
        "    \n",
        "    for param in teacher_model.parameters():\n",
        "        param.requires_grad = False\n",
        "    \n",
        "    pooling = TopKLogitPooling(k_percent=0.1)\n",
        "    criterion = PatchDistillationLoss(alpha=0.5)\n",
        "    print(f\"✓ Pooling and loss initialized\")\n",
        "    \n",
        "    return student_model, teacher_model, pooling, criterion\n",
        "\n",
        "print(\"✓ Data loading and initialization utilities defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_training_history(history, figsize=(15, 5)):\n",
        "    '''Plot training history.'''\n",
        "    fig, axes = plt.subplots(1, 3, figsize=figsize)\n",
        "    \n",
        "    axes[0].plot(history['train_loss'], label='Train')\n",
        "    if 'val_loss' in history:\n",
        "        axes[0].plot(history['val_loss'], label='Val')\n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    axes[0].set_ylabel('Loss')\n",
        "    axes[0].set_title('Training Loss')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True)\n",
        "    \n",
        "    if 'val_acc' in history:\n",
        "        axes[1].plot(history['val_acc'])\n",
        "        axes[1].set_xlabel('Epoch')\n",
        "        axes[1].set_ylabel('Accuracy')\n",
        "        axes[1].set_title('Validation Accuracy')\n",
        "        axes[1].grid(True)\n",
        "    \n",
        "    if 'val_auc' in history:\n",
        "        axes[2].plot(history['val_auc'])\n",
        "        axes[2].set_xlabel('Epoch')\n",
        "        axes[2].set_ylabel('AUC')\n",
        "        axes[2].set_title('Validation AUC')\n",
        "        axes[2].grid(True)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "def print_model_summary(model):\n",
        "    '''Print model architecture.'''\n",
        "    print('\\nModel Architecture:')\n",
        "    print('='*80)\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f'Total parameters: {total_params:,}')\n",
        "    print(f'Trainable parameters: {trainable_params:,}')\n",
        "\n",
        "def compute_model_size(model):\n",
        "    '''Compute model size in MB.'''\n",
        "    param_size = 0\n",
        "    for param in model.parameters():\n",
        "        param_size += param.nelement() * param.element_size()\n",
        "    return (param_size) / 1024 / 1024\n",
        "\n",
        "print(\"✓ Helper functions defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Usage Examples\n",
        "\n",
        "### Step 1: Prepare Data\n",
        "```python\n",
        "dataset_root = \"/content/drive/MyDrive/deepfake-patch-audit/data\"\n",
        "train_loader, val_loader = create_sample_data_loaders(dataset_root, batch_size=16)\n",
        "```\n",
        "\n",
        "### Step 2: Initialize Models\n",
        "```python\n",
        "student, teacher, pooling, criterion = initialize_training_pipeline()\n",
        "```\n",
        "\n",
        "### Step 3: Train (Single-Stage)\n",
        "```python\n",
        "trainer = PatchStudentTrainer(student, teacher, train_loader, val_loader, \n",
        "                             criterion, pooling, device=DEVICE)\n",
        "history = trainer.train(epochs=20)\n",
        "```\n",
        "\n",
        "### Step 4: Train (Two-Stage)\n",
        "```python\n",
        "trainer = TwoStagePatchStudentTrainer(student, teacher, train_loader, val_loader,\n",
        "                                     criterion, pooling, device=DEVICE)\n",
        "history = trainer.train(epochs_s1=5, epochs_s2=20)\n",
        "```\n",
        "\n",
        "### Step 5: Inference & Visualization\n",
        "```python\n",
        "pipeline = InferencePipeline(student, pooling, device=DEVICE)\n",
        "result = pipeline.predict(\"image.jpg\")\n",
        "fig = pipeline.visualize_heatmap(\"image.jpg\", result)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "### Step 6: Quantization\n",
        "```python\n",
        "quantizer = ImprovedDynamicRangeQuantizer(bits=8, per_channel=True)\n",
        "quantized_model, params = quantizer.quantize_model(student)\n",
        "print(quantizer.get_quantization_report(params))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "✓ All components loaded successfully!\n",
        "\n",
        "**Available Classes:**\n",
        "- `BaseDataset`: Dataset loading (directory/CSV modes)\n",
        "- `TinyLaDeDa`: Student model (1,297 parameters)\n",
        "- `TopKLogitPooling`: Spatial pooling layer\n",
        "- `PatchDistillationLoss`: MSE + BCE loss\n",
        "- `PatchStudentTrainer`: Single-stage training\n",
        "- `TwoStagePatchStudentTrainer`: Two-stage fine-tuning\n",
        "- `InferencePipeline`: Inference with heatmaps\n",
        "- `ImprovedDynamicRangeQuantizer`: Int8 quantization\n",
        "\n",
        "**Next Steps:**\n",
        "1. Mount Google Drive and prepare dataset\n",
        "2. Run `create_sample_data_loaders()` with your dataset path\n",
        "3. Initialize models with `initialize_training_pipeline()`\n",
        "4. Train with `PatchStudentTrainer` or `TwoStagePatchStudentTrainer`\n",
        "5. Run inference with `InferencePipeline`\n",
        "6. Quantize with `ImprovedDynamicRangeQuantizer`"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
